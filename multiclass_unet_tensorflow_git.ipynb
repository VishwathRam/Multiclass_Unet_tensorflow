{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VishwathRam/Multiclass_Unet_tensorflow/blob/main/multiclass_unet_tensorflow_git.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vuIBP4iOeZD6",
        "outputId": "ea036578-00ba-4fb8-cf84-8841c2de3b99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Train: 52 - Valid: 6 - Test: 6\n",
            "(4, 64, 1024, 3) (4, 64, 1024, 3)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "W = 1024 \n",
        "H = 64\n",
        "\n",
        "def process_data(data_path, file_path):\n",
        "    df = pd.read_csv(file_path, sep=\" \", header=None)\n",
        "    names = df[0].values\n",
        "\n",
        "    images = [os.path.join(data_path, f\"/content/drive/MyDrive/Projects/Lincoln_unet/input1/train/{name}.jpg\") for name in names]\n",
        "    masks = [os.path.join(data_path, f\"/content/drive/MyDrive/Projects/Lincoln_unet/input1/mask/{name}.tif\") for name in names]\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "def load_data(path):\n",
        "    train_valid_path = os.path.join(path, \"/content/drive/MyDrive/Projects/Lincoln_unet/input1/trainval.txt\")\n",
        "    test_path = os.path.join(path, \"/content/drive/MyDrive/Projects/Lincoln_unet/input1/test.txt\")\n",
        "\n",
        "    train_x, train_y = process_data(path, train_valid_path)\n",
        "    test_x, test_y = process_data(path, test_path)\n",
        "\n",
        "    train_x, valid_x = train_test_split(train_x, test_size=0.1, random_state=42)\n",
        "    train_y, valid_y = train_test_split(train_y, test_size=0.1, random_state=42)\n",
        "\n",
        "    return (train_x, train_y), (valid_x, valid_y), (test_x, test_y)\n",
        "\n",
        "def read_image(x):\n",
        "    x = cv2.imread(x, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    x = x / 255.0\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(x):\n",
        "    # x = cv2.imread(x, cv2.IMREAD_GRAYSCALE)\n",
        "    # x = cv2.resize(x, (W, H))\n",
        "    # x = x - 1\n",
        "    # x = x.astype(np.int32)\n",
        "    # return x\n",
        "    BGR_classes = {'a' : [ 0, 0, 0],\n",
        "                   'b' : [255,  255, 255],\n",
        "                   'c' : [36, 28, 237]} # in RGB #237,28,36\n",
        "\n",
        "    bin_classes = ['a', 'b', 'c']\n",
        "    mask = cv2.imread(x)\n",
        "    cls_mask = np.zeros(mask.shape)  \n",
        "    cls_mask[mask == BGR_classes['a']] = bin_classes.index('a')\n",
        "    cls_mask[mask == BGR_classes['b']] = bin_classes.index('b')\n",
        "    cls_mask[mask == BGR_classes['c']] = bin_classes.index('c')\n",
        "    cls_mask = cls_mask[:,:,0]\n",
        "    cls_mask = cv2.resize(cls_mask, (1024,64)) \n",
        "    cls_mask = cls_mask.astype(np.int32)\n",
        "    return cls_mask\n",
        "\n",
        "\n",
        "def tf_dataset(x, y, batch=4):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    #print(x)\n",
        "    #print(len(dataset), dataset)\n",
        "    #dataset = dataset.shuffle(buffer_size=5000)\n",
        "    dataset = dataset.map(preprocess)#(x,y))\n",
        "    dataset = dataset.batch(batch)\n",
        "    #dataset = dataset.repeat()\n",
        "    #dataset = dataset.prefetch(2)\n",
        "    return dataset\n",
        "\n",
        "def preprocess(x, y):\n",
        "    def f(x, y):\n",
        "        x = x.decode('UTF-8')\n",
        "        y = y.decode('UTF-8')\n",
        "\n",
        "        image = read_image(x)\n",
        "        mask = read_mask(y)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n",
        "    mask = tf.one_hot(mask, 3, dtype=tf.int32)\n",
        "    image.set_shape([H, W, 3])\n",
        "    mask.set_shape([H, W, 3])\n",
        "\n",
        "    return image, mask\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    path = \"/content/drive/MyDrive\"\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "    print(f\"Dataset: Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
        "\n",
        "    dataset = tf_dataset(train_x, train_y, batch=4)\n",
        "    for x, y in dataset:\n",
        "        print(x.shape, y.shape) ## (8, 256, 256, 3), (8, 256, 256, 3)\n",
        "        break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQIOxIVPeZB5",
        "outputId": "c0693895-50e8-4502-8b38-ca47b6f1cd6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 64, 1024, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 64, 1024, 16  448         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 64, 1024, 16  64         ['conv2d[0][0]']                 \n",
            " alization)                     )                                                                 \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 64, 1024, 16  0           ['batch_normalization[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 64, 1024, 16  2320        ['activation[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 64, 1024, 16  64         ['conv2d_1[0][0]']               \n",
            " rmalization)                   )                                                                 \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 64, 1024, 16  0           ['batch_normalization_1[0][0]']  \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 32, 512, 16)  0           ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 32, 512, 32)  4640        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 32, 512, 32)  128        ['conv2d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 32, 512, 32)  0           ['batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 32, 512, 32)  9248        ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 32, 512, 32)  128        ['conv2d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_3 (Activation)      (None, 32, 512, 32)  0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 16, 256, 32)  0          ['activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 256, 48)  13872       ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 16, 256, 48)  192        ['conv2d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_4 (Activation)      (None, 16, 256, 48)  0           ['batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 16, 256, 48)  20784       ['activation_4[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 16, 256, 48)  192        ['conv2d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_5 (Activation)      (None, 16, 256, 48)  0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 8, 128, 48)  0           ['activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_6 (Conv2D)              (None, 8, 128, 64)   27712       ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 8, 128, 64)  256         ['conv2d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_6 (Activation)      (None, 8, 128, 64)   0           ['batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_7 (Conv2D)              (None, 8, 128, 64)   36928       ['activation_6[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 8, 128, 64)  256         ['conv2d_7[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_7 (Activation)      (None, 8, 128, 64)   0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " max_pooling2d_3 (MaxPooling2D)  (None, 4, 64, 64)   0           ['activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_8 (Conv2D)              (None, 4, 64, 128)   73856       ['max_pooling2d_3[0][0]']        \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 4, 64, 128)  512         ['conv2d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_8 (Activation)      (None, 4, 64, 128)   0           ['batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " conv2d_9 (Conv2D)              (None, 4, 64, 128)   147584      ['activation_8[0][0]']           \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 4, 64, 128)  512         ['conv2d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " activation_9 (Activation)      (None, 4, 64, 128)   0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 8, 128, 128)  0           ['activation_9[0][0]']           \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 8, 128, 192)  0           ['up_sampling2d[0][0]',          \n",
            "                                                                  'activation_7[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_10 (Conv2D)             (None, 8, 128, 64)   110656      ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 8, 128, 64)  256         ['conv2d_10[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_10 (Activation)     (None, 8, 128, 64)   0           ['batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_11 (Conv2D)             (None, 8, 128, 64)   36928       ['activation_10[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 8, 128, 64)  256         ['conv2d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_11 (Activation)     (None, 8, 128, 64)   0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 16, 256, 64)  0          ['activation_11[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_1 (Concatenate)    (None, 16, 256, 112  0           ['up_sampling2d_1[0][0]',        \n",
            "                                )                                 'activation_5[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_12 (Conv2D)             (None, 16, 256, 48)  48432       ['concatenate_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 16, 256, 48)  192        ['conv2d_12[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_12 (Activation)     (None, 16, 256, 48)  0           ['batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_13 (Conv2D)             (None, 16, 256, 48)  20784       ['activation_12[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_13 (BatchN  (None, 16, 256, 48)  192        ['conv2d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_13 (Activation)     (None, 16, 256, 48)  0           ['batch_normalization_13[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_2 (UpSampling2D)  (None, 32, 512, 48)  0          ['activation_13[0][0]']          \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 32, 512, 80)  0           ['up_sampling2d_2[0][0]',        \n",
            "                                                                  'activation_3[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_14 (Conv2D)             (None, 32, 512, 32)  23072       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_14 (BatchN  (None, 32, 512, 32)  128        ['conv2d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_14 (Activation)     (None, 32, 512, 32)  0           ['batch_normalization_14[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_15 (Conv2D)             (None, 32, 512, 32)  9248        ['activation_14[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_15 (BatchN  (None, 32, 512, 32)  128        ['conv2d_15[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " activation_15 (Activation)     (None, 32, 512, 32)  0           ['batch_normalization_15[0][0]'] \n",
            "                                                                                                  \n",
            " up_sampling2d_3 (UpSampling2D)  (None, 64, 1024, 32  0          ['activation_15[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 64, 1024, 48  0           ['up_sampling2d_3[0][0]',        \n",
            "                                )                                 'activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " conv2d_16 (Conv2D)             (None, 64, 1024, 16  6928        ['concatenate_3[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_16 (BatchN  (None, 64, 1024, 16  64         ['conv2d_16[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_16 (Activation)     (None, 64, 1024, 16  0           ['batch_normalization_16[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_17 (Conv2D)             (None, 64, 1024, 16  2320        ['activation_16[0][0]']          \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " batch_normalization_17 (BatchN  (None, 64, 1024, 16  64         ['conv2d_17[0][0]']              \n",
            " ormalization)                  )                                                                 \n",
            "                                                                                                  \n",
            " activation_17 (Activation)     (None, 64, 1024, 16  0           ['batch_normalization_17[0][0]'] \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_18 (Conv2D)             (None, 64, 1024, 3)  51          ['activation_17[0][0]']          \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 599,395\n",
            "Trainable params: 597,603\n",
            "Non-trainable params: 1,792\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "def conv_block(inputs, filters, pool=True):\n",
        "    x = Conv2D(filters, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    x = Conv2D(filters, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation(\"relu\")(x)\n",
        "\n",
        "    if pool == True:\n",
        "        p = MaxPool2D((2, 2))(x)\n",
        "        return x, p\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "def build_unet(shape, num_classes):\n",
        "    inputs = Input(shape)\n",
        "\n",
        "    \"\"\" Encoder \"\"\"\n",
        "    x1, p1 = conv_block(inputs, 16, pool=True)\n",
        "    x2, p2 = conv_block(p1, 32, pool=True)\n",
        "    x3, p3 = conv_block(p2, 48, pool=True)\n",
        "    x4, p4 = conv_block(p3, 64, pool=True)\n",
        "\n",
        "    \"\"\" Bridge \"\"\"\n",
        "    b1 = conv_block(p4, 128, pool=False)\n",
        "\n",
        "    \"\"\" Decoder \"\"\"\n",
        "    u1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b1)\n",
        "    c1 = Concatenate()([u1, x4])\n",
        "    x5 = conv_block(c1, 64, pool=False)\n",
        "\n",
        "    u2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x5)\n",
        "    c2 = Concatenate()([u2, x3])\n",
        "    x6 = conv_block(c2, 48, pool=False)\n",
        "\n",
        "    u3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x6)\n",
        "    c3 = Concatenate()([u3, x2])\n",
        "    x7 = conv_block(c3, 32, pool=False)\n",
        "\n",
        "    u4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x7)\n",
        "    c4 = Concatenate()([u4, x1])\n",
        "    x8 = conv_block(c4, 16, pool=False)\n",
        "\n",
        "    \"\"\" Output layer \"\"\"\n",
        "    output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
        "\n",
        "    return Model(inputs, output)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    model = build_unet((64, 1024, 3), 3)#model = build_unet((64, 1024, 3), 10)\n",
        "    model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAYr5DZJR-48",
        "outputId": "3cac18a9-d676-408e-d81a-0b63a9bed6ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 29.3 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 30.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 22.1 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 17.9 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 20.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 19.6 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 22.6 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████                          | 204 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 235 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 317 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 378 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 409 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 440 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 471 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 491 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 552 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 583 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 614 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 634 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 645 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 665 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 675 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 706 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 727 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 757 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 778 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 788 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 808 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 819 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 839 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 849 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 880 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 901 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 911 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 931 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 942 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 952 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 962 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 983 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 993 kB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.0 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.0 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.1 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.1 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.1 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.1 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.1 MB 20.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 20.6 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q -U tensorflow-addons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJ079f7h7YFX",
        "outputId": "95c20c88-3b9d-4506-8d41-fc2060a47439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset: Train: 52 - Valid: 6 - Test: 6\n",
            "Epoch 1/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.2149 - accuracy: 0.5770\n",
            "Epoch 1: saving model to model.h5\n",
            "13/13 [==============================] - 107s 6s/step - loss: 0.2149 - accuracy: 0.5770 - val_loss: 0.1689 - val_accuracy: 0.8332 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.8451\n",
            "Epoch 2: saving model to model.h5\n",
            "13/13 [==============================] - 13s 1s/step - loss: 0.0945 - accuracy: 0.8451 - val_loss: 0.1517 - val_accuracy: 0.7848 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0777 - accuracy: 0.8834\n",
            "Epoch 3: saving model to model.h5\n",
            "13/13 [==============================] - 11s 885ms/step - loss: 0.0777 - accuracy: 0.8834 - val_loss: 0.1344 - val_accuracy: 0.8639 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0631 - accuracy: 0.9045\n",
            "Epoch 4: saving model to model.h5\n",
            "13/13 [==============================] - 9s 709ms/step - loss: 0.0631 - accuracy: 0.9045 - val_loss: 0.1292 - val_accuracy: 0.7848 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0552 - accuracy: 0.9148\n",
            "Epoch 5: saving model to model.h5\n",
            "13/13 [==============================] - 8s 687ms/step - loss: 0.0552 - accuracy: 0.9148 - val_loss: 0.0937 - val_accuracy: 0.8827 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9242\n",
            "Epoch 6: saving model to model.h5\n",
            "13/13 [==============================] - 9s 750ms/step - loss: 0.0489 - accuracy: 0.9242 - val_loss: 0.0949 - val_accuracy: 0.8606 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9301\n",
            "Epoch 7: saving model to model.h5\n",
            "13/13 [==============================] - 9s 747ms/step - loss: 0.0448 - accuracy: 0.9301 - val_loss: 0.1021 - val_accuracy: 0.8433 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0413 - accuracy: 0.9348\n",
            "Epoch 8: saving model to model.h5\n",
            "13/13 [==============================] - 9s 772ms/step - loss: 0.0413 - accuracy: 0.9348 - val_loss: 0.1014 - val_accuracy: 0.8639 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0396 - accuracy: 0.9364\n",
            "Epoch 9: saving model to model.h5\n",
            "\n",
            "Epoch 9: ReduceLROnPlateau reducing learning rate to 5.0000002374872565e-05.\n",
            "13/13 [==============================] - 8s 665ms/step - loss: 0.0396 - accuracy: 0.9364 - val_loss: 0.1163 - val_accuracy: 0.8346 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0368 - accuracy: 0.9410\n",
            "Epoch 10: saving model to model.h5\n",
            "13/13 [==============================] - 9s 721ms/step - loss: 0.0368 - accuracy: 0.9410 - val_loss: 0.1091 - val_accuracy: 0.8521 - lr: 5.0000e-05\n",
            "Epoch 11/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9441\n",
            "Epoch 11: saving model to model.h5\n",
            "13/13 [==============================] - 9s 748ms/step - loss: 0.0353 - accuracy: 0.9441 - val_loss: 0.1000 - val_accuracy: 0.8610 - lr: 5.0000e-05\n",
            "Epoch 12/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9443\n",
            "Epoch 12: saving model to model.h5\n",
            "13/13 [==============================] - 9s 736ms/step - loss: 0.0349 - accuracy: 0.9443 - val_loss: 0.1195 - val_accuracy: 0.8336 - lr: 5.0000e-05\n",
            "Epoch 13/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9441\n",
            "Epoch 13: saving model to model.h5\n",
            "\n",
            "Epoch 13: ReduceLROnPlateau reducing learning rate to 2.5000001187436284e-06.\n",
            "13/13 [==============================] - 9s 717ms/step - loss: 0.0350 - accuracy: 0.9441 - val_loss: 0.1130 - val_accuracy: 0.8368 - lr: 5.0000e-05\n",
            "Epoch 14/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9438\n",
            "Epoch 14: saving model to model.h5\n",
            "13/13 [==============================] - 8s 684ms/step - loss: 0.0352 - accuracy: 0.9438 - val_loss: 0.1381 - val_accuracy: 0.7918 - lr: 2.5000e-06\n",
            "Epoch 15/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9444\n",
            "Epoch 15: saving model to model.h5\n",
            "13/13 [==============================] - 9s 742ms/step - loss: 0.0350 - accuracy: 0.9444 - val_loss: 0.0790 - val_accuracy: 0.8893 - lr: 2.5000e-06\n",
            "Epoch 16/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9436\n",
            "Epoch 16: saving model to model.h5\n",
            "13/13 [==============================] - 9s 745ms/step - loss: 0.0352 - accuracy: 0.9436 - val_loss: 0.0910 - val_accuracy: 0.8645 - lr: 2.5000e-06\n",
            "Epoch 17/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9456\n",
            "Epoch 17: saving model to model.h5\n",
            "13/13 [==============================] - 9s 765ms/step - loss: 0.0343 - accuracy: 0.9456 - val_loss: 0.0718 - val_accuracy: 0.8991 - lr: 2.5000e-06\n",
            "Epoch 18/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9449\n",
            "Epoch 18: saving model to model.h5\n",
            "13/13 [==============================] - 8s 677ms/step - loss: 0.0346 - accuracy: 0.9449 - val_loss: 0.0877 - val_accuracy: 0.8609 - lr: 2.5000e-06\n",
            "Epoch 19/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9452\n",
            "Epoch 19: saving model to model.h5\n",
            "13/13 [==============================] - 9s 710ms/step - loss: 0.0346 - accuracy: 0.9452 - val_loss: 0.0868 - val_accuracy: 0.8561 - lr: 2.5000e-06\n",
            "Epoch 20/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9446\n",
            "Epoch 20: saving model to model.h5\n",
            "13/13 [==============================] - 9s 733ms/step - loss: 0.0350 - accuracy: 0.9446 - val_loss: 0.0726 - val_accuracy: 0.8861 - lr: 2.5000e-06\n",
            "Epoch 21/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9456\n",
            "Epoch 21: saving model to model.h5\n",
            "\n",
            "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.2500000821091816e-07.\n",
            "13/13 [==============================] - 9s 755ms/step - loss: 0.0344 - accuracy: 0.9456 - val_loss: 0.0896 - val_accuracy: 0.8539 - lr: 2.5000e-06\n",
            "Epoch 22/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9440\n",
            "Epoch 22: saving model to model.h5\n",
            "13/13 [==============================] - 9s 736ms/step - loss: 0.0352 - accuracy: 0.9440 - val_loss: 0.0592 - val_accuracy: 0.9188 - lr: 1.2500e-07\n",
            "Epoch 23/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9462\n",
            "Epoch 23: saving model to model.h5\n",
            "13/13 [==============================] - 8s 659ms/step - loss: 0.0340 - accuracy: 0.9462 - val_loss: 0.0622 - val_accuracy: 0.9115 - lr: 1.2500e-07\n",
            "Epoch 24/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9453\n",
            "Epoch 24: saving model to model.h5\n",
            "13/13 [==============================] - 9s 737ms/step - loss: 0.0344 - accuracy: 0.9453 - val_loss: 0.0555 - val_accuracy: 0.9224 - lr: 1.2500e-07\n",
            "Epoch 25/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9452\n",
            "Epoch 25: saving model to model.h5\n",
            "13/13 [==============================] - 9s 738ms/step - loss: 0.0345 - accuracy: 0.9452 - val_loss: 0.0488 - val_accuracy: 0.9303 - lr: 1.2500e-07\n",
            "Epoch 26/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9460\n",
            "Epoch 26: saving model to model.h5\n",
            "13/13 [==============================] - 9s 756ms/step - loss: 0.0342 - accuracy: 0.9460 - val_loss: 0.0523 - val_accuracy: 0.9198 - lr: 1.2500e-07\n",
            "Epoch 27/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9441\n",
            "Epoch 27: saving model to model.h5\n",
            "13/13 [==============================] - 8s 701ms/step - loss: 0.0350 - accuracy: 0.9441 - val_loss: 0.0483 - val_accuracy: 0.9301 - lr: 1.2500e-07\n",
            "Epoch 28/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9461\n",
            "Epoch 28: saving model to model.h5\n",
            "13/13 [==============================] - 8s 682ms/step - loss: 0.0340 - accuracy: 0.9461 - val_loss: 0.0529 - val_accuracy: 0.9190 - lr: 1.2500e-07\n",
            "Epoch 29/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9451\n",
            "Epoch 29: saving model to model.h5\n",
            "13/13 [==============================] - 9s 735ms/step - loss: 0.0345 - accuracy: 0.9451 - val_loss: 0.0483 - val_accuracy: 0.9216 - lr: 1.2500e-07\n",
            "Epoch 30/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9455\n",
            "Epoch 30: saving model to model.h5\n",
            "13/13 [==============================] - 9s 733ms/step - loss: 0.0342 - accuracy: 0.9455 - val_loss: 0.0476 - val_accuracy: 0.9271 - lr: 1.2500e-07\n",
            "Epoch 31/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9457\n",
            "Epoch 31: saving model to model.h5\n",
            "13/13 [==============================] - 9s 722ms/step - loss: 0.0341 - accuracy: 0.9457 - val_loss: 0.0470 - val_accuracy: 0.9271 - lr: 1.2500e-07\n",
            "Epoch 32/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9458\n",
            "Epoch 32: saving model to model.h5\n",
            "13/13 [==============================] - 8s 658ms/step - loss: 0.0341 - accuracy: 0.9458 - val_loss: 0.0518 - val_accuracy: 0.9172 - lr: 1.2500e-07\n",
            "Epoch 33/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0350 - accuracy: 0.9441\n",
            "Epoch 33: saving model to model.h5\n",
            "13/13 [==============================] - 9s 738ms/step - loss: 0.0350 - accuracy: 0.9441 - val_loss: 0.0382 - val_accuracy: 0.9450 - lr: 1.2500e-07\n",
            "Epoch 34/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9443\n",
            "Epoch 34: saving model to model.h5\n",
            "13/13 [==============================] - 9s 746ms/step - loss: 0.0348 - accuracy: 0.9443 - val_loss: 0.0431 - val_accuracy: 0.9328 - lr: 1.2500e-07\n",
            "Epoch 35/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9442\n",
            "Epoch 35: saving model to model.h5\n",
            "13/13 [==============================] - 9s 752ms/step - loss: 0.0349 - accuracy: 0.9442 - val_loss: 0.0420 - val_accuracy: 0.9314 - lr: 1.2500e-07\n",
            "Epoch 36/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9457\n",
            "Epoch 36: saving model to model.h5\n",
            "13/13 [==============================] - 9s 707ms/step - loss: 0.0342 - accuracy: 0.9457 - val_loss: 0.0423 - val_accuracy: 0.9330 - lr: 1.2500e-07\n",
            "Epoch 37/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9461\n",
            "Epoch 37: saving model to model.h5\n",
            "13/13 [==============================] - 8s 694ms/step - loss: 0.0341 - accuracy: 0.9461 - val_loss: 0.0378 - val_accuracy: 0.9395 - lr: 1.2500e-07\n",
            "Epoch 38/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9461\n",
            "Epoch 38: saving model to model.h5\n",
            "13/13 [==============================] - 9s 741ms/step - loss: 0.0341 - accuracy: 0.9461 - val_loss: 0.0392 - val_accuracy: 0.9384 - lr: 1.2500e-07\n",
            "Epoch 39/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9445\n",
            "Epoch 39: saving model to model.h5\n",
            "13/13 [==============================] - 9s 732ms/step - loss: 0.0349 - accuracy: 0.9445 - val_loss: 0.0372 - val_accuracy: 0.9436 - lr: 1.2500e-07\n",
            "Epoch 40/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9438\n",
            "Epoch 40: saving model to model.h5\n",
            "13/13 [==============================] - 9s 743ms/step - loss: 0.0352 - accuracy: 0.9438 - val_loss: 0.0381 - val_accuracy: 0.9403 - lr: 1.2500e-07\n",
            "Epoch 41/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9448\n",
            "Epoch 41: saving model to model.h5\n",
            "13/13 [==============================] - 8s 647ms/step - loss: 0.0348 - accuracy: 0.9448 - val_loss: 0.0423 - val_accuracy: 0.9300 - lr: 1.2500e-07\n",
            "Epoch 42/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9446\n",
            "Epoch 42: saving model to model.h5\n",
            "13/13 [==============================] - 9s 724ms/step - loss: 0.0346 - accuracy: 0.9446 - val_loss: 0.0410 - val_accuracy: 0.9365 - lr: 1.2500e-07\n",
            "Epoch 43/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9442\n",
            "Epoch 43: saving model to model.h5\n",
            "\n",
            "Epoch 43: ReduceLROnPlateau reducing learning rate to 1e-08.\n",
            "13/13 [==============================] - 9s 752ms/step - loss: 0.0348 - accuracy: 0.9442 - val_loss: 0.0430 - val_accuracy: 0.9295 - lr: 1.2500e-07\n",
            "Epoch 44/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9453\n",
            "Epoch 44: saving model to model.h5\n",
            "13/13 [==============================] - 9s 745ms/step - loss: 0.0345 - accuracy: 0.9453 - val_loss: 0.0347 - val_accuracy: 0.9488 - lr: 1.0000e-08\n",
            "Epoch 45/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9451\n",
            "Epoch 45: saving model to model.h5\n",
            "13/13 [==============================] - 8s 697ms/step - loss: 0.0344 - accuracy: 0.9451 - val_loss: 0.0390 - val_accuracy: 0.9379 - lr: 1.0000e-08\n",
            "Epoch 46/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9455\n",
            "Epoch 46: saving model to model.h5\n",
            "13/13 [==============================] - 9s 707ms/step - loss: 0.0343 - accuracy: 0.9455 - val_loss: 0.0418 - val_accuracy: 0.9301 - lr: 1.0000e-08\n",
            "Epoch 47/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0349 - accuracy: 0.9446\n",
            "Epoch 47: saving model to model.h5\n",
            "13/13 [==============================] - 9s 740ms/step - loss: 0.0349 - accuracy: 0.9446 - val_loss: 0.0356 - val_accuracy: 0.9430 - lr: 1.0000e-08\n",
            "Epoch 48/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9453\n",
            "Epoch 48: saving model to model.h5\n",
            "13/13 [==============================] - 9s 739ms/step - loss: 0.0345 - accuracy: 0.9453 - val_loss: 0.0420 - val_accuracy: 0.9283 - lr: 1.0000e-08\n",
            "Epoch 49/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0342 - accuracy: 0.9458\n",
            "Epoch 49: saving model to model.h5\n",
            "13/13 [==============================] - 9s 761ms/step - loss: 0.0342 - accuracy: 0.9458 - val_loss: 0.0389 - val_accuracy: 0.9352 - lr: 1.0000e-08\n",
            "Epoch 50/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9455\n",
            "Epoch 50: saving model to model.h5\n",
            "13/13 [==============================] - 8s 637ms/step - loss: 0.0344 - accuracy: 0.9455 - val_loss: 0.0343 - val_accuracy: 0.9487 - lr: 1.0000e-08\n",
            "Epoch 51/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9452\n",
            "Epoch 51: saving model to model.h5\n",
            "13/13 [==============================] - 9s 721ms/step - loss: 0.0344 - accuracy: 0.9452 - val_loss: 0.0356 - val_accuracy: 0.9430 - lr: 1.0000e-08\n",
            "Epoch 52/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9461\n",
            "Epoch 52: saving model to model.h5\n",
            "13/13 [==============================] - 9s 742ms/step - loss: 0.0341 - accuracy: 0.9461 - val_loss: 0.0418 - val_accuracy: 0.9286 - lr: 1.0000e-08\n",
            "Epoch 53/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9451\n",
            "Epoch 53: saving model to model.h5\n",
            "13/13 [==============================] - 9s 736ms/step - loss: 0.0344 - accuracy: 0.9451 - val_loss: 0.0356 - val_accuracy: 0.9430 - lr: 1.0000e-08\n",
            "Epoch 54/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0341 - accuracy: 0.9458\n",
            "Epoch 54: saving model to model.h5\n",
            "13/13 [==============================] - 9s 712ms/step - loss: 0.0341 - accuracy: 0.9458 - val_loss: 0.0406 - val_accuracy: 0.9330 - lr: 1.0000e-08\n",
            "Epoch 55/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0351 - accuracy: 0.9437\n",
            "Epoch 55: saving model to model.h5\n",
            "13/13 [==============================] - 8s 669ms/step - loss: 0.0351 - accuracy: 0.9437 - val_loss: 0.0353 - val_accuracy: 0.9453 - lr: 1.0000e-08\n",
            "Epoch 56/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0348 - accuracy: 0.9441\n",
            "Epoch 56: saving model to model.h5\n",
            "13/13 [==============================] - 9s 740ms/step - loss: 0.0348 - accuracy: 0.9441 - val_loss: 0.0392 - val_accuracy: 0.9346 - lr: 1.0000e-08\n",
            "Epoch 57/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0344 - accuracy: 0.9452\n",
            "Epoch 57: saving model to model.h5\n",
            "13/13 [==============================] - 9s 740ms/step - loss: 0.0344 - accuracy: 0.9452 - val_loss: 0.0402 - val_accuracy: 0.9345 - lr: 1.0000e-08\n",
            "Epoch 58/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0355 - accuracy: 0.9430\n",
            "Epoch 58: saving model to model.h5\n",
            "13/13 [==============================] - 9s 750ms/step - loss: 0.0355 - accuracy: 0.9430 - val_loss: 0.0378 - val_accuracy: 0.9400 - lr: 1.0000e-08\n",
            "Epoch 59/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9450\n",
            "Epoch 59: saving model to model.h5\n",
            "13/13 [==============================] - 8s 673ms/step - loss: 0.0345 - accuracy: 0.9450 - val_loss: 0.0416 - val_accuracy: 0.9289 - lr: 1.0000e-08\n",
            "Epoch 60/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9448\n",
            "Epoch 60: saving model to model.h5\n",
            "13/13 [==============================] - 9s 704ms/step - loss: 0.0346 - accuracy: 0.9448 - val_loss: 0.0419 - val_accuracy: 0.9294 - lr: 1.0000e-08\n",
            "Epoch 61/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9447\n",
            "Epoch 61: saving model to model.h5\n",
            "13/13 [==============================] - 9s 742ms/step - loss: 0.0346 - accuracy: 0.9447 - val_loss: 0.0350 - val_accuracy: 0.9450 - lr: 1.0000e-08\n",
            "Epoch 62/100\n",
            "13/13 [==============================] - ETA: 0s - loss: 0.0346 - accuracy: 0.9451\n",
            "Epoch 62: saving model to model.h5\n",
            "13/13 [==============================] - 9s 735ms/step - loss: 0.0346 - accuracy: 0.9451 - val_loss: 0.0390 - val_accuracy: 0.9367 - lr: 1.0000e-08\n",
            "Epoch 62: early stopping\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "#!pip install -q -U tensorflow-addons\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "#from data import load_data, tf_dataset\n",
        "#from model import build_unet\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\" Seeding \"\"\"\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "    \"\"\" Dataset \"\"\"\n",
        "    path = \"/content/drive/MyDrive\"\n",
        "    (train_x, train_y), (valid_x, valid_y), (test_x, test_y) = load_data(path)\n",
        "    print(f\"Dataset: Train: {len(train_x)} - Valid: {len(valid_x)} - Test: {len(test_x)}\")\n",
        "\n",
        "    \"\"\" Hyperparameters \"\"\"\n",
        "    shape = (64, 1024, 3)\n",
        "    num_classes = 3\n",
        "    lr = 1e-3\n",
        "    batch_size = 4\n",
        "    epochs = 100\n",
        "\n",
        "    \"\"\" Model \"\"\"\n",
        "    model = build_unet(shape, num_classes)\n",
        "    model.compile(loss=tfa.losses.SigmoidFocalCrossEntropy(), optimizer=tf.keras.optimizers.Adam(lr),metrics=['accuracy'])#\"categorical_crossentropy\"\n",
        "\n",
        "    train_dataset = tf_dataset(train_x, train_y, batch=batch_size)\n",
        "    valid_dataset = tf_dataset(valid_x, valid_y, batch=batch_size)\n",
        "\n",
        "    train_steps = len(train_x)//batch_size\n",
        "    valid_steps = len(valid_x)//batch_size\n",
        "\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(\"model.h5\", verbose=1, save_best_model=True),\n",
        "        ReduceLROnPlateau(monitor=\"val_loss\", patience=4, factor=0.05, verbose=1, min_lr=1e-8),#patience=3, min_lr=1e-6, factor=0.1\n",
        "        EarlyStopping(monitor=\"val_loss\", patience=12, verbose=1)#patience=5\n",
        "    ]\n",
        "\n",
        "    model.fit(train_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_data=valid_dataset,\n",
        "        validation_steps=valid_steps,\n",
        "        epochs=epochs,\n",
        "        callbacks=callbacks\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S9QvfCAC4hRI"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "#DO NOT USE\n",
        "\n",
        "\n",
        "model.save('/content/drive/MyDrive/Projects/Lincoln_unet/tf1_10.hdf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "byHaE0Kh4gwk"
      },
      "outputs": [],
      "source": [
        "#Load previously saved model\n",
        "#Also can use: model = tf.keras.models.load_model(\"model.h5\")\n",
        "\n",
        "from keras.models import load_model\n",
        "model = load_model(\"/content/drive/MyDrive/Projects/Lincoln_unet/tf1_100.hdf5\", compile=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "KT0L0Wt3FDAX",
        "outputId": "2ccbd912-4361-4327-de29-88aece01bda5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6\n",
            "6\n",
            "(1, 64, 1024, 3) (1, 64, 1024, 3)\n",
            "(1, 64, 1024, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAscAAAA7CAYAAACXOSdlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d5xlRZn//65zbr63b+c03T2huyfCkAdmCJKTGFeCqChmlHXXn4qBNX0Vw7q6iyusYAAVEXEBEUYRMJIEGcLkHLp7OqfbfXM69fvjnKq53dOTU+Oez+vVr773nnOqnlPnPFWf56mnnhJSSly4cOHChQsXLly4cAHGsRbAhQsXLly4cOHChYvpApccu3DhwoULFy5cuHDhwCXHLly4cOHChQsXLlw4cMmxCxcuXLhw4cKFCxcOXHLswoULFy5cuHDhwoUDlxy7cOHChQsXLly4cOHAJcevMQghEkKI1mMthwsXLg4M0013hRDXCyGeOdrXunCxNwghfiKEuMX5fI4QYuNBlnOHEOILh1e61y7c9jgwuOT4MMIZ/NSfJYRIl3x/50GU9xchxAdKf5NSRqSU2w6f1LquLwshfn64y3Xh4rUAV3dduNh/CCF2lOhIv0NoI4e7Hinl01LK+fshz27GmpTyBinlVw+3TIcTU/UTB1nOeUKInXs757XQHtMJLjk+jHAGv4iUMgJ0Am8s+e3eYy2fCxcupoaruy5cHDDe6OjLKcBpwOcnnyCE8Bx1qVy4OAxwyfFRgBDCEEJ8VgixVQgxLIT4lRCiyjkWEEL83Pk9JoR4UQhRL4T4GnAOcJtjnd/mnC+FEO3O558IIW4XQvxWCBEXQrwghGgrqfcSIcRGIcSYEOJ/hBB/3V8r1anno0KIzU7ZXxVCtAkhnhNCjDv34HPOrRRCLBdCDAohRp3PzSVlzRFCPOWU8wdH5p+XHF/qlBsTQqwUQpx3GJrdhYtDxmtRdyfJr2SPCyHWCSHeuvsp4janng1CiAtLDpQLIX4shOgVQnQLIW4RQpgH0Ywu/oEhpewGHgOOB/2e3yiE2Axsdn57gxDiVUdPnhNCnKCuF0KcLIR42XlH7wcCJccmeESFEC1CiIecsWbYeXcXAncAyxx9iznn6vAM5/sHhRBbhBAjQohHhBAzSo5JIcQNzngXc3RTTHW/Qgi/EOJWIUSP83erEMJfKq8Q4pNCiAFHd967h3L21E8sEEI86ci5UQhxdck1r3f0OO7o5KeEEGGn/WeIXbNdM6aorzRcRcn56RI53+KUv8mp++aSa08XQvzNaZtep919Jcf32l8JId4nhFgvbH7wuBBi1lRtMp3gkuOjg48BbwHOBWYAo8DtzrH3AOVAC1AN3ACkpZT/BjwN/LPjvfrnPZT9duD/AZXAFuBrAEKIGuAB4HNOuRuBMw9Q7kuBU4GlwKeBHwDvcmQ9HrjWOc8A7gZmATOBNHBbSTm/AP7uyPFl4Dp1QAjRBPwWuAWoAj4FPCiEqD1AWV24OBJ4requwlbsAbjcqevnQojGkuNnOOfUAF8CHhIO+Qd+AhSAduBk4BLgkKeAXfxjQQjRArweeKXk57dgv1uLhBAnA3cBH8Z+n+8EHnFIpg94GLgHu///X+Bte6jHBJYDHcBsoAn4pZRyPbbu/c3Rt4oprr0A+AZwNdDolPHLSae9AVgCnOCcd+kebvnfsMfEk4ATgdOZ6DVvwNa3JuD9wO1CiMrJhUzVTzhE90nsMbMOu4/4HyHEIueyHwMfllKWYY/Bf5JSJoHLgZ6S2a6ePcheigZsQ6QJ+CLwQ+zx/VTsPuMLQog5zrlF4P/D7ieWARcCH4V991dCiDcDNwP/BNQ693zffsh3TOGS46ODG4B/k1LulFJmsQnilcKecspjv1DtUsqilPIlKeX4AZT9aynl36WUBeBebIUFu7NaK6V8yDn230DfAcr9LSnluJRyLbAGeEJKuU1KOYZtqZ4MIKUcllI+KKVMSSnj2IP8uQBCiJnYHc4XpZQ5KeUzwCMldbwL+J2U8ndSSktK+SSwwpHfhYtjjdeq7gIgpfxfKWWPo1v3Y3vyTi85ZQC4VUqZd45vBK4QQtQ7cnxcSpmUUg4A/4U9WLtwAfCw46V9Bvgr8PWSY9+QUo5IKdPAh4A7pZQvOHryUyCLTTCXAl52vYMPAC/uob7TsQ3Um5x3MuOMJ/uDdwJ3SSlfdvT4c9ie5tkl53xTShmTUnYCf2aXPk5V1leklANSykFso/O6kuN553heSvk7IAHsM27awRuAHVLKu6WUBSnlK8CDwFUlZS8SQkSllKNSypf3s9ypkAe+JqXMYxsKNcB3pZRxZ8xfh03+cfq25x2ZdmAbOOc65eyrv7oB+31Y7xz/OnDSdPceu+T46GAW8GtnSiIGrMe2xOqxLebHgV86UzTfEkJ4D6Ds0pcwBahFETOALnVASimBvQbsT4H+ks/pKb5HAIQQISHEnUKIDiHEOPAUUOFY+jOAESllquTarpLPs4CrVNs47XM2tnXvwsWxxmtVdwEQQrxb7JrOjmF7m2pKTul2ylfocOqfhU1aekuuvRPbm+XCBcBbpJQVUspZUsqPOkRYYXIf/8lJfXwL9ns2g6nfwanQAnQ4BOtAMaO0XCllAhjG9poq7Ekf91oWu3RGYXiSjHsrazJmAWdMaqt3Ynt5wfaqvx7ocEIXlu1nuVNhWEpZdD6rZ7enMX6esMMl+5wx/uvs6kf21V/NAr5bcj8jgGBi2087uOT46KALuNzpSNRfQErZ7ViX/09KuQh7KuINwLud6+QeS9w3eoHSuF9R+v0w45PYlvEZUsoo8DpVrSNHlRAiVHJ+S8nnLuCeSW0TllJ+8wjJ6sLFgeA1q7uOZ+aHwD8D1c508xpsvVRocspXmAn0YN93Fqgpue+olPK4A74bF/8XUfr+d2F7KEt1KCSlvA/7XZ/qHZwKXcBMMfUiv33pWw82SQPACV+oBrr3dSP7KotdOnMwmCx3F/DXSW0VkVJ+BEBK+aKU8s3YRurDwK/2UM7hxveBDcBcZ4y/mV39yL76qy7sUJDSewpKKZ87wjIfElxyfHRwB/A1NY0ghKh14nAQQpwvhFjseFnHsac6LOe6fuBg86L+FljsBNl7gBvZZX0ebpRhW5kxJ17xS+qAlLIDO0ziy0IIn2PpvrHk2p8DbxRCXCqEMIW9yOk8UbKgz4WLY4jXiu4aju6oPz8Qxh40Bx1534uzaKoEdcC/CCG8QoirgIXYYU69wBPAd4QQUWEvTGwTQpyLCxcHhh8CNwghzhA2wkKIK4QQZcDfsOPa1Tv4T0wM+ynF37GJ2DedMgJCiLOcY/1AsyhZJDYJ9wHvFUKc5OjG14EXnBCBA8V9wOedvqAGO173YFMpTu4nlgPzhBDXOe3hFUIsEUIsdMbPdwohyp1QiHEm9jfVQojyg5RjXyhz6ksIIRYAHyk5tq/+6g7gc0KI40Av9L2KaQ6XHB8dfBc7zvYJIUQceB57sQLYL9ED2C/eeuzYrXtKrrtS2Cs8//tAKpRSDmHHKX0Le/poETZJzR7arUyJW4EgMIR9b7+fdPyd2EH8w9gL7+5XckgpuwAVsD+IbWXehPtuupgeeK3o7rXYBqr62yqlXAd8B5uA9AOLgWcnXfcCMBdbd78GXCmlHHaOvRvwYccejjr36oY7uTggSClXAB/EXqQ9ir349HrnWA57odb12NPt1wAP7aGcIrZjpR073eJO53yAPwFrgT4hxNAU1/4B+AJ2/G4v0MbBx8/fgq2Pq4DVwMvObweDCf2EtNfsXOLI1oMd6vHvgN85/zpghxPacAP22IqUcgM2ad/mhC/slq3iEPEp4B1AHNvYuV8d2Fd/JaX8tXMPv3TkXoO9gHBaQ0wM9XHxjwohhIHdmbxTSvnnYyzL/cAGKeWX9nmyCxf/xzGddNeFCxcu9oZ/lP7K9c79A8MJVahwppFUjNDzx0COJc6UrCGEuAzbU/zw0ZbDhYvXCqaL7rpw4cLFvvCP2F8dEjkWQlwm7MTPW4QQnz1cQrk4bFiGncN0CHs66i2TVhQfLTQAf8FOafPfwEecFDUujjJcnX3NYLrorotjCFdfXbxG8A/XXx10WIWzCGUTcDG2C/1F4Fonzs2FCxfTDK7OunDx2oGrry5cHDsciuf4dGCLtDeFyGEnkX7z4RHLhQsXRwCuzrpw8dqBq68uXBwjTJUvcH/RxMRE3zvZtYp76so8Hun12jny98djXXqOEALDMPZ57aEsMJRSIoSY8F/VPfl7qVxi6i3YJxyffN5kOUvrtCxrcjG7nVsqy+R2UvWUlqXar/TY5PspPTbVfewP1H1MlmN/rpuqnj19L31Ok+s1TXNCnVJKCoXCHt8nhcntPvn5l/6ujkkpMU2TYDBIsVikUCjougzDmLI9SjE2NjYkpTxaW2UfkM7W1NTI2bNn73fhql2KxSL5fH5Ce5umidfr3a3N9/e9OhaY/N5OZ1n/r0M9q2KxuNuxqXT9YJ/lSy+99A+jry5cTBdMHpsno1AoUCwW8fv9ux3bGw5FXw+FHO8XhBAfwt4+Eq/XS3t7uyYQEwTxePD5fPh8PjweDx6PR5M5wzAwTZNIJILX6yWXy+HxeMjn85okGYZBPp/Hsiw8Hs8E8mSaJoZhUCwWsSyLYrE4obNUBCeXy2lZSgd3v9+Pz+fTZDMcDuPxePSDKisrI51O6/KFELoO0zQpFouYponP56OmpoZsNksoFKJYLDIwMIBlWfh8PizLwrIsXbfX69XXqrIVCoWCbh/LsrRspW2rSFomk6FQKOiXLpfL6XZQbaPqNU0Tj8ejyYzP5yMSiRAOhzFNE7CJTulnJUOhUCCXy5HP5ykUCliWpYmq3+/XBFHdh3rOijSZpollWZpUlt6TZVnkcjktbz6fxzAMfayUhGYyGfx+P4Zh4PV6dT1K1pJ3E0C3uzqu2kANtKoeIQT5fJ5kMqnbTghBIBCYQICLxSKxWIxAIEA+n6e7u5uRkRFCoRA+nw8hBB6PrXoPP/zwnnaDOiYo1deZM2eyYsWKCcctyyKdTpNMJunt7aWjo4Pe3l5Wr17N+vXrGRoaoq+vj1gsNqHD8/v91NTUMGPGxAxDLS0tzJkzh+OPP5558+bR2NhIIBAgk8nQ39+vyygUCmzatEm3+9y5c/F6vQghqK2tJRTatcfM+Pg4IyMj+vvWrVtJpVJs3bqV0dHRCfW3tbVRU1NDe3s7XV1dpFIpent7Wbt2LR0dHRPuoaKigsnko7Kykra2tgm/lZeXM3OmvY9BMBikvr5+wvHe3l7Ky8u1zEIIIpGI1ikFwzB2I3V7gjJKkskk+XyeeDzOjh07eOmll6iqqppywBFC0NbWRltbG1VVVVpHVVmALk9hbGyM0dFRenp6GB4e1r8HAgHa29unrEe1vUJrayvhcJh8Ps/mzZspFos0NjbS3NxMQ8Ou9KiJRIKVK1dOeJYK2WyWdevWaYN048aN5HI5uru7yWZ3ZbwzDIPa2lpaW1uZMWMGpmnS1tbGvHnzuOSSSw6YJAshXlP6OtTbS8czz3LCm9+E6fGQyWRIpVK7lZPL5fQYND4+TigUoqamBuXMEkKQSCTIZDKT69djsvoeDofxer16XC11YGSzWZLJJGVlZXr8mvzeSylJp9MUCgV8Pjtt8djYGDt37kRKSTgcpqmpiXw+TyaTIZvNsmPHDsbHx1m1ahX9/f3MmjULr9dLR0cHV1xxBdFolNHRUVKpFGNjY1RXV+/WF3k8HmbMmDGlzgUCAUzTJJPJ6HtUY4bC5PFlX1B6lk6nyWazDA4Okkwm93h+WVkZ1dXVeL1ePR5P1lcpJfF4fAJXSCaTDA4O7lWWiooKKioq9PfJfahCKBSirq6ORCLB8PAwNTU1GIbBwMAAUko91ikMDw8zMjLC7Nmz6ezs3K3/BRgYGCAej9PY2EhLSwsf//jHqaqqYu3atWzdupXy8nJOOeUU4vE4wWCQ8vJyDMMgl8vpMWBPOBR9PRRy3M3Enc6amWK3GSnlD4AfAITDYenxeJBSEggEqKio0OS31OuWy+VIJBLa46fIqdfrJRKJaGIZDAapqbF3MGxra+OZZ56hv7+fVCqFYRhkMhny+TwVFRUUCgWy2awmTDNnziSdTrN48WIGBgYAu9NOp3fFkA8MDNDf38/8+fNZvHgxnZ2dJBIJ8vk86XSaaDRKXV0d5eXlBINB1q5dS1lZGUIIkskk4+PjAPr85uZmjj/+eN15m6apZSsvL2doaIh4PE5FRQXhcJjh4WE8Hg/ZbBafz0d5eTl9fX0IIXTHEQwGCQQCFAoFEomEJg8Kqg1yuZzuyEpJaqmx4PF4dCenOjdVdiaT0R7BVCpFOBzWBD6dThOJRLRhY1kWoVBIk9JSQ0ERTUU6FCHPZrOawBYKBbxeL/l8XhNtZZwoIymVSulylTFgGIYmn6XefiEEsVgMsDsYdY/qHQoEAgSDQXw+nyb+igjn8/kJhsn4+DixWAzDMCgrK8Pv9yOlJBgMTjDOGhoaCIVCRCIRli5dyjPPPMPWrVu1EQhognwUsU+dLdXX0047TYJNiHt6evjTn/7E448/zurVqxkcHCQWi2lDa1/I5/MkEgl27Ngx5XH1bpaXl+vBVumPI9cEklbaKarnoKDIe2ndkz0TpbMCgUBAG1+l55UaaQcCpUtKzmg0OoEgjI2NEQwGJ8jc3NxMIBCYUM7MmTOpqqrarzrHx8fZtm0bPT09pFIp0uk08Xh8NyfEZHi9XiorK2lvb+eUU07BMAwSiQRbtmxBSklvb+8EMpVKpUilUtooVVAG31QDlTJwFZTjo/SZmqaJ3++nvLxcl5HJZIjFYvv1fhmGQUVFBc3NzdTU1HDZZZfh8/mora1l9uzZzJkzRxsJe5JzGuKg9FVKSSqVsh04kQiphnru/slPeO6551i5cqUe70pRKBR0351Op/H7/Zx22mnMnDmTXC7H4sWLWb58OevXr9/t2rKyMuLx+C4hm5upqKjA4/Fw3XXXUVZWxo4dO1iwYAH33HMPY2NjtLW1sXnzZjweDxdeeCFXXnklK1asYMWKFeTzeR577DESiQSNjY2Ul5fT39/Pzp07aWxsJJ1OawNQ9dGJRAKv10tNTQ09PT0Ui0Wt5/fccw+1tbVs27aNYrE4Zb9bWVnJBRdcwPr160kkEvqdr6ioIJvNaqN9y5YtmKZJY2PjBPIuhGDu3LlEIhEqKioIhUITDL1SWJbFhg0bGBkZYdOmTfT39zM2NkY8Hp9g2E2G3++nrKyMUCjEnDlzmD9/vnYUbdiwgWKxSLFYpKura4K+ZbPZCc9nKgSDQcLhsP4+uQ9V8Pl8lJWVkc1mSSQSRCIRDMPQffXkfgHQxobiO8oQbmxsZNGiRVx22WW0trbS3NxMMBjUz6e5uZnKykpM0yQUCk1wJpSWe6RwKAvyPNiLBS7EVtgXgXdIKdfu6ZpgMCgXLFiAaZqk02mqqqrIZDLaExwMBolGo3g8Hnp7ezX5U6StrKyMmTNnUl5eTj6fJxaLUVVVxdjYGIFAgFwuh2EYBINBpJR0dHQwMDCgiZbqlA3D4OSTT2bz5s2aeGcyGZqbmznhhBOYN28eUkruv/9+Ojs7WbhwIa2trSSTSWKxGGNjY0gpmTFjBosXL8bn8zEyMkKxWCQajeoBsLe3l7GxMcLhMO3t7VRVVWmLC3ZZqqlUSg/2qVSK8fFxhoeHGRsbY+7cuYCtUJWVldp6b2pqIp1OMz4+TkdHByMjI9rgKC8v197abdu2MTAwwMyZM4nH40gpicViui3C4TB+v19bm2NjY/h8PmbNmkVvb6/2BJeVlemX3u/3k0qlkFISCoXI5XLaIFFTH8qyU17pyVPsqVRKExKv16u9xkIIstks5eXljI6O6oFV3U8gENCkO5vNkslkKCsrIxAIaMNGWeOWZVFdXU0mkyGZTGoSbBiG7mii0SiRSES3sfJExONx7XFXZEd1AiMjIxQKBWpqaohGo3i9Xu39Vgaeeg+VB76xsZGXXnqJrVu3UigU9O+//vWvX5JSnnZQSniAOFCdPfnkk+Utt9zC8uXL+c1vfkN/f79+noZh0NbWxhVXXMGOHTt44oknJpAoj8fDkiVLsCyL9evXU1tbqweOwcFBBgcHyWazLFy4kHA4zJo1axgaGsI0Te2Jb2hoIJPJMDAwoAe1UChEJpMhHo/j8/l2I74KinyZpskJJ5xAQ0MD5557Lj6fj4aGBu644w46Ojr41Kc+xbJly3j00Ue5//772bRpE9XV1bzjHe/g0ksvZevWrTz77LN0dnYyPj6uiUdzczN9fX1s27ZNv9/TKWd8U1MTixcv5umnn9a6cKhQBqfqN5ShPBnKIxgKhQgEAtTX1yOlZPv27aRSqT2GW3m9XlqamwkBWBYEgwivl3g8TiKRYN68eVx00UVEo1Esy+KJJ54gFotx+umnc95553HqqafS2Nio+4cjQYCFENNaX2+//XZ++9vf8vjvfkcoGCSZybB+wwYA6urqmD9/PpWVleQ3bWbe6BhPlYUZzNiG1Jw5c2hoaOD555/X/aPC+Pg4NTU1zJ07V88ODQ0NkUqlSCaThEIh7YAKBAJ6PAuHw9ozGgwGSSQSXHDBBbS0tHDfffcxPj6Ox+OhtraW4eFhcrkc1dXVlJWVsWzZMt761reybNkyurq6+OMf/8hZZ51FJBLhtttuY9WqVWzduhUTwRVveiPve9/7iMfjPPTQQzz99NOMjY1RWVnJVVddpfnEo48+qr2cpZ7tQqGgHVulRrnqR5zncdj0yOfzTSDClZWVNDU16Xc2m83S399PMpncp4G7t3r8fr82wovFIolEYsI5pQTT7/dTWVlJdXU1AH19fRNmhwA9RgcCAT3T4PV6ufzyy/W4NzQ0xMjICMcffzxLlixhwYIF2vnR2tqqvd+q7iNpqB6Kvh7SJiBCiNdj745mAndJKb+2t/N9Pp+sqakhn88TiUSYN2+e9qzMmDFDNyCgPX2RSIRgMIgQgoqKCqLRKOPj49rzEo1GNVELBAK6szYMQ5OrbDZLPp/XVl5ZWZn2gno8HlKpFKZpUl5eTqFQ0Eocj8f1QF1ZWUksFiMajVJfX08+nycajWIYBpFIhGQyqb3V1dXV5HI5crmcVkS/3082m8Xv9xMKhejv79f3pUIXVAiE8qgUCgUaGhooFot6illZ8oVCgbGxMQYGBgiHw9TV1RGPx0mn0wSDQbxeL+vWrUMIob1x4+PjpNNpRkZGNJGNRqNUVlZiGAahUIjR0VE6Ojq0F7isrIyWlhZaWlq01wjszlKRaeWBVp5kQHuCfT4fY2NjmlCHQiEdahEIBPD7/ZpsWZbFwMCAtsgVUQqFQpqger1eMpmMNqqKxaKuU5FZFb7g8/lIpVIMDQ0hhKC6uprGxsYJIR7K4FFGTzabndBxKij5lDcrl8tRUVGh20mRbuWtUB4x5Y1RRl53dzfbtm3T04mPPfbYURts4cB0NhgMSuWNaGho4M1vfjNXXnklxWIRn8/HiSeeSHl5Oel0mh07dtDdvcupFQqFOPnkk7Esi+HhYSorK/UzLRQKug1ra2vxer0MDg6yadMmgsEgDQ0NCCGoqqoimUzS399PJpMhGAxSVVXF+Pg4TzzxBIsXL6a7u5uHHnpIX3veeefR2tpKe3s7sViM0dFRrr76at1fqOczPDyMlJLq6mo9AA4PD7Nq1Spamptpa2+fMDDm83mK6TSYJhmn/xobG2PNmjXac7V161b8fj89PT0sX75cGxDNzc00NTWp9tezDQ8//DDr1q0jEAhw/vnnU1tby+DgIGeeeSbd3d1s3LiRuGP8ptJpBgYGWLJkCY2NjQwMDNDU1MQDDzygjUI1sF1zzTVcffXVLFy4kFdeeYXh4WE2bNhALpejt7eXp556ikAgwEknncSsWbO0Vy4YDNLd3a3bBWDu3LlEo1EAZs+ercMvZs6cyfDwMN///vfZtGkTF110EX6/n0gkwty5czFNk1mzZhEKBinP55HxBI+tWc2fnnqKs88+m0AgwPLly0kmk7S3t1NdXc0pp5zCcfki1pe+Crk8gRs/jP/aq7UnvLa2Vs8MKR2TUk7w3h1pHE1y7NS33/paW1srjUSCcwwP7yivJvrWN5GaPYsOr8nSs86itbWV8vJyO4QwkcBMJimWl5PJ5Uin01RWVuL1ehkYGNCOKQXVdwcCAT12xmIx0uk0HR0dNDU1acdPXV2dnhX2+/1kMhlNgtevX8+KFSvYsmWLLjsajWonUCgU4qKLLqKuro7KysoJs5xq3AuFQrrv7t65EyuRoO344/E6JFDpsvJsVlVVaU+yMsIHBwfZuXMnc+fOJR6Pc9ddd5FOJGid0cSa7duYP3++bouFCxfS0tLChg0b6OvrY8WKFdTV1WGlUoxns8ycNUuP//l8nlhfH37DIFYsMnPmTNrb28nn8/j9frZs2cKGDRvw+XzU19ezePFili5dymWXXTYhPKtQKDA8PMzmzZtZuXIlnZ2dlJeXa0dOLBbTY2zpbFxTUxMNDQ0YhsG8efNoaWnRuqz6zf7+fqqrq/F4PCxcuFCPnyrsTel7T08P27Zt02Vns1k2bNjA7NmzaW9vp7KykpUrV/LOd76TWbNm8eCDDzJv3jztwT6aeqmiDCaH6RiGcWzI8YHC6/XKiooKIpEI8+fPp6GhQXv3/H6/jttVcaKlMZ8jIyNUVFTQ1NSEz+ebMJWuQgOU4pZ6JhSByufzjI+PYxgGVVVV2lNZSmRUCEE0GtXTfIrkqumC8vJympqaGB8f196riooKfW5fXx9SSm3xpdNp1q9fT11dHW1tbdozqmL3amtraWho0Pdumib19fV6usLr9WoLM5/PEwwGtWIEg0FN0BRxy2Qy2nOsOoZEIqFjnjdt2kRvby/RaJRoNDqBSKq2U3Kr2FtAt4EiDKouRVpVLJjy2Kjprmg0SmdnJ16vV09fq1hiZTSoZ6nCF9RMgiLJPp+PQCCAlJLx8XHtgVJxcVJKPB6PbjPllc1mswwMDGgPgmpPZUQpYyKXy+kpOhWGURoGAuh2SaVSxGIxisWijnVV9186ZVca70uP2ocAACAASURBVC6lpK+vj8HBQdLptPaQSClZu3btUR1sDwQVFRXS7/fzgQ98gBtvvFF3ugcKWSxCJgOmCRII7CKpWBaULBTV10iJ1dWNCAUR1VPHzKrzioUCuUwGw+vVBHi/ZZu0ELS4bQepf/82vje8Ht8bLt/Vl1gWqS/fgve8c/FdcO5ey1QGOdjeGGFZkMmCzwuOR031TUNDQ9pzpuQpbePcS68wdtv3KZ61jP6TT2DeokW6nwO44447uPfee1m0aBGf+tSnqK2tpaa6GlQb5PNgGHbbJ5Pg95N19FwNXqgxQAhio6P41m3Ak0jgu/B8yOXB70NMmoqWUkIuRyqZxHBCk8jlwetBlK7nSKWJX/9BimvXEfr6V/C96Yop20x7zO5/gPQdP8L/1jcReP97wCFCRxP5fJ5HH32UwcFB3v/+90+Yhj/a5PhAMLO6Rj7si9BcXkHZDR8g8NEPQUnM8P5CSmm/E2Lvi80nXyNjY7a+7mPR1J44x8E8Z5nJkLzpZvzvuhbP6adNKENmMuDx7PbuTiVPPp+nWCjgQZAeHibQ3w+mB3H8ogl9ugpbqKmpQeTyJPM5KquqtEe5Z/nvkLffSaBpBoV/+zTVLS06XEF5pbdv3055eTk1NTXa8aP7w2IREAiPOaFvmtxPlbahTKagUECUR/fZjpPDy/Z4TiaDKDGO9oTt27fzq1/9itNPP52zzjprV59yFCGlJPbyK3z1q7fQacCCRYsY7OvnuuvfwznnnHPQ+npUgx6VN6iqqkqTMb/fTyKRYPv27fT19VEoFJgzZw6GYeiAb2XBKet27dq1Ol6pdCrAsiz6+vqoqanRi9xUDHMul6OjowMhBK2trQQCAT19XrqYxzAM7R1VU+YqrEAtFFDTRhUVFTruNZ1OMzo6yuDgoF4EokhiV1cXvb29doM7nsRcLkdPTw/bt2+ntbWVeDyuveO9vb2EQiEdyqDCEzweD4ODg2QyGbZt20YkEuF1r3udjnUtFAo0NjYSDAZJp9Ok02l6e3t1DGcul2PLli089dRTNDc3c+659iDf1dXFyMiIXiyowi/a2tooFAps376dTCZDVVUVL7/8MtFolEWLFrFp0yYaGxs1SVRxjt3d3Xpqqq6uTnuDa2pqGBkZwefz0dzcjN/vnxDusnPnTtLpNOFwmEwmQ09PjzYeqqqq8Hq9Oh5ZXaMWx+XzeU2AAR3q4fP5mDdvnp7+y+VyxGIxxsfHdciI8vgrQqyQyWT0zIEi4Mqr3NjYSCQS0R2MItLKqCuNU87lcmzcuFEbFeo9ONjpsqOF1tZWHnnkERobG6dcNJP/01+xurvxX3s1whmEFayBAQqvrsL7urOxBgZJffkW8HiQQ8MEbvgAvksuAiD7k5/jWboEz3GLJlZuWaS/9R2svn4iP7gdKiumJNBycIj8/Q8gfF78H3r/gZGAZIr0//wAEfDje+ubMBobsEZHyP/hT1idO/FdciGogV4IfJdeDM7znzAIS2mTX4f069CuZIriq6sorF5D5kd3Y86bR+TW/4Ay2/vjHRmlIZPFaLVnzaRlIQoF8HhsQlsokLvjR3j++Bc8zz7Pcff8GE8wSHHjJgp/fQbv0tP58IJFXH/TZ6Crm0hrK/h8ZL73fZCSwIffT/KmmzHnthP44HtJ/PMn8L3hcgJXvlXLXuzaSfob30amU/hefxkVb30TiZ/eS+rZ5xD/8XUyP/4pvre9Bf87rtmtbTM/uQfT58N//XUU128g9YWvEPjnG/Ce97pd5wYDhD7zSftdOPtM2ws4PILV04t5/KLdyvRedjHmiYsx58/br2epCYVhYG3ZhtE2BzHpXT1QPP3001x33XV87GMf2+29n86oqa1lwQdvwHfxBZjHLZrQDrJYJPfo75CDg/iuuQpRFpn4DqczyFgM0VCP7O0j9dVvYi6cj/9d12JUVe61XmlZWNu2k/ryLfjf/S5bb/aCgzV2rKEhcg8vx1wwH89ZS+1yPB5EJELuscfxnD6RA+Ue/R34fPjf/IZ9yuPz+ZBeL4WnnkHcfQ+Jp5/Fc+rJlN179661K9ksHtOktbVV33dEEXDTpJDPM/TLX9G+ZRtiewfhjVvwLVyIHBkl99gTmHNmEUylWSQlhhSYs2fb+tDXj5XLYTTNIP3tW/EuOwPP687G2rwFo3WOXb4ixcUiuYd+Q2HtenyXXIhn2Rnk/vdB8s89T+R7/4mYtG5hT20vCwWKXTsxZs+a+nns5zOaM2cOn/nMZ/br3CMFGRtD3PRvfGzzFjbc8F4KJyzGOzRMy6SF0AeK/SLHQogdQBwoAgUp5WlCiCrgfmA2sAO4Wkq5+1LEEiiPoQr6Hx8fp1gs6ilyFdOXzWaprq6eEP+TSCTo7++nt7eXQqGgpzKVx1nFK6qYWuX1DAQCjI2NMTg4qDu6tWvXagtHDXRqumJ0dFSvSG1sbMTn8+nFbCpcQXkIe3t79WIsKSX9/f0MDAwQDAZ1fX6/n2AwiGVZWka16lXdW09Pj57SisVi+t7UtFYkEiGdTut4x9raWu0J7u7uplgsIqVk48aN1NXVcdxxx2FZFlu2bNFkvb29XXuO4/E4mzZtYvbs2fT19bFu3Tqy2SzRaJShoSHtvY/H4/j9foaHh7W3Uy3GUXG3amWzSrWSSCTYuHGjji1UHq5CoUA8HtfPWYXLqNg0Fc8rhCAejxOLxYjH49qbPj4+rhd+pNNpUqmUXuioDIPu7m6d2UMRYSVDNpvVZFkZAIlEQhskKtxDLfQIhUIkk0nC4fAE40nF0YVCIR13qQi+Wu1bGrOm4qtN06S5uVm/F4o8r1mzZn9U8IBwuPTVMAyam5unPiglxVWrEfV1NpGbDEuS+dFPyP/laUJfupnI9/4Tq6fX7pArK5GWBULY5Lmnh/zTz2IuWoBQmRUMAzweCn9fQfKznyf8H9+AaBlksshsFlEexeraSeLGj1NcuZrgJz52wO0kcznyTz9LcY1NXj0nnYiIRMCSmLNn2iR1V5uCEGR+/FMiS0+fcEwODpG+/U5CN30cK19AxmIUVq9FRMJYW7fjOXsZnpdfxWybAwGHbBcKJL/0VYRpEv7efyENQe6R35K562cYdbUE//WjmMcfhzmvnfyf/4pRX4dRV4scGSXx4Y9hbd9B2u+3vTvSQpSXU7z8Usx57XiWnIo1OGQ/huERZHYteL34r38XnoULdmuHwksvY/X0Uli1Bs/S0wl86H0UzzgN84TFmHPbsTo6p2y/wLuuBSfMofDSKxReWUnuN8vxvu4cMHelXPScejKeU0/e1ZbRKIZv6lXmRnk5Rnn5np+Zmm2wLPB4sDq7KG7bjjmzheSnbybyg9sQdXV7eer7hlo/8Za3vOWoea0Ph84akTDBT/zL1DJnc2Tv+xWFF14kv+IVIrd+C0o8g8X1G0h++mbCt9+K2ToH7wXnkv/bC4igTbas8XGE3z+lV1gOjxC//kNYPb0Ebvjgrt+lhGwOvI6xl0wiC0WMij0/371BZrJkfnQ3oqICz3e+QWjRQjBNQp//LDK1++Ix7zln7ZoV2U8Y7W2EPv8Zco/+DqOl2Z5xcZD58U8x57bju/Qim6fc9TMy9/4S/5uuIPCvN2J6PJx41ZWkN29DRKOYrXOgaDH63dswHv8DRiRCcfsO8HjwX/M2Qicutkmo1wuWbeD533ENhpNkwGhrnbJvFbU1WFu3UXilBs+yM/Bf9Ta855+7y5DfH+TzYO3Fg78Pkj2tYJqYrbOpv+xiZt94AyIc2vc1+4H9CqtwFPc0KeVQyW/fAkaklN8U9raWlVLKvZoQPp9PzpgxQ3v41Er3bDarF3CozxUVFXpBgAqBGB8f14uzhBDak6em8guFgvb0qVCJiooK7S1U8UuKXCtvnyLKajpfxa5GIhH9XU3Jq9hltZBNETsVK6wW5qnUL6qjUrKprBsqPCKdTutplWg0qqf4FQmHXUHzhUKBqqoqHUOkMiMosqUIo2qPvr4+vditoaFBp5yLx+Oa4KmQFRUfHAgEJuTnHR4e1gvOqqurdVupeGsln4odtiyL7u5uurq6qKqqYv78+ZimSSwW0xknVKy18v56PB7i8ThdXV0YhkFNTQ39/f1YlkV9fb1ebJnJZBgdHZ2QWq003ZVaCKhmC1TcU2kWAEWUVRiLer5qkaNq82AwqJ+ZMrrU9FppbJMKZ/H5fDqWNJFIaG9/IBBgfHyc7u5uAoEAXV122lLlsX7yyScP+zTt4dLX0047TU5ODaW8pIW16yCVwjz+OMQkr65atEEyRbGjE6O5CTk6SvKmmymsXovn+EWU3Xs3SMjc8UPSt90BhTzm/HmU/eKnGNVVtiH4pVvI3v0zMAx8b7gco6WZwgsvIpMpvBdfQP4Pf6a4zl4971l6OmV33YmUFsLnw+rtw+rsQjTUY85tnzjVX7SQw8OIaBkylSL93f8h+7N7oTSjwpJT8V5wHmbbHDxnLUOUlUGxiLWzm8KLL2E01ONZthTyefJPPU32wYcBQXHLVqyeHkhnEGURwt/+Jt5LL7LDScTEKVJr23asoWHIZjGam8j84C6K27YjMxlCX/gcntNOgWyO/PMvYLa3YTTNgHye7P0PIMJhRCiEuXA+5HJgGBizZpJ7+FHyzz2P2dyE78q32uRZCER1lXoPdnuehRdeJPnJzyKCQSJ3fg+zrdU2XnI5e/CWEiaFq8hcjsKrqxBlEcwF87E2b8EaGsacP3eXgXOYoAix1dFpk7unngEhCH/n3+1QFcsCCXJ0FFFXe8h1b926lRtvvJEHHnhAO00UjlRYxeHQ2cn6KtXiMeUtHI2R/NwXIJsjctt/ISK7shPIYpH8758g+8jvCH/jK4iKcmQ8jnAyrRS7dpL934fwLj0dz2mnIEqmz2U2S+KGf6Hw0stEbr8VfD7bEF67nvxzfyM3exaRExeTf+xJfG+/EuuUk/CHwxgN9RQti+LmrXgbGxAV5VM+u1KOkv3Jz8nc8wt65rUx+z++gcfrtcMW6+vtTA7hsB7npZQU83niA4NU1NchDYP46CjeUIiVK1dSV1fHjBkz9MLeYiZDMBLBcHiF8wx2yZDN2h52nxcjFCL34MPkn3sez5JT8V/9NoRpIotFrJ5eRMCPcEiujCcgnYaAn+KqNYi6WsymJgiHyGWzFP72Aq9u3kz0jCUcv3jxhL5qKtghTXmQltZLKaVdh88HU6SUk5aFtWUrBAIYLc1HPVTpSMMaG7dDeibNYB6Kvh5KWMWbgfOczz8F/gLs079eGm+qPpfmNVb5AxVpVeQDdqUJKU0Z5i2J4SsNQVBEbWhoSHtcS8tT8buZTEanEitdKa9Ijgr7UAuJVD5gv9+vF4ipY2oaXhGw0lhURZ7Ly8t1TklFutVq0t7eXkzTJBwOayNAla9iEcfHx/X9l5Jr5Y1WKVuEsFeUlpWVTVjIohYEKmIopaSyspJQKKTTsqn77+vr02Q6EAgQi8Vobm7WYRzJZJKqqipt1ChvfXNzM6lUivr6ep1hYvv27YyMjBCNRpk3b55+vslkkkQiQWdnJzt37iQajZLJZPB6vTrtmnpmPT09+v4VAVN5pyORCJZl6cWZaoGEal8VAqGejUrJVl1drVPFANrYUO1d+qc6XUAbJCqlm/quFgipHJjq2c+aNYvOzk5SqZQ2JI4yDkpfSyEti/wTfyBzx48prF4DhQLm8YsIffnzeJecqgeU1MOPIletIfT+9+A5biGZn91L+jvfxWxrtYlWoQDFIvnnXsCKjeG96HxkbMwmsY4hI4TAf83bsDo6sYaGKax4GVa8rGXJPfBrAIwZjbZsmSzFLVtJfvErkMtj9fUhE0mMmmoid96G56QT9LWFFS+RvOlmvK87m9BXvkDo5puQiQS5hx/ddc7Lr1J48SUwTTxnLKHs7jshECT/12dsMg9EH/gFVkcn6W9/l+KOHXZoRWl75XKISNjxOju/JVPkHn+S/J//ikynKaxcjRwYRFRUEPzkvxD66heRyZSOH8Tvw7vsDHQBXi/+d12rdbTwtxfA68Vzyknkn/wjyZu/CGm7v8w/9Sxl995F5p77KK5bj+fkE/GcsBhz8XGa3Agh8Jy4mPCt38KorsaYM9u+9i9Pk/7mt/GcdjKhmz+tn4ssFCiseJnsL+4n99vfI8oiBN7zLvzvew/eeXMP5HU6IOQefJjUt/4TY0YjIhTCe8G5diy0iqcGexbjEFEoFHjyySf57Gc/OyG11THCIels9v4HyP/xL/guOh/PGUuwhkfwv/0qvGcutUlUCYRpYrS2UnjmOZKf+AyR73/Xfo9MD0TCGHW1iGCA/PN/t/W0tmbXxT4fwX/5KJmf3GMbeJ1dWAMDCMNE5vOYa9aR/v2TdujL9wYZCfipOW4RwWuuJNE8g+xHPkawupr0jR8mcvwiwnV1E8hbNpXi2f99gCVnn03Z9e/Cf9U/EU0myT30GzY89DB/7+mmu72VRDJBtKWFd9/0KWY7+ci3/f5xdt7/AK2zZlH/zrfz+wcfJJ5I8uIv76c7m8F3/HFUVVSQ6+7mKmly4Xf/k9DS0yeS4kwWBIw9/wKZL3+N9eEgjy+cy5lnn80bv/PNiUTTMLAa7OwsXpwML9EyiNphmaK9jWIiiREMIIA//Owear/67wxkM3zRb3DfH56kdu5crO4eCs//HXPRQsyF8ycS5lyOwkuvIPx+zJNOANOk8MKLpL50C+bi4wh94XO6/5BSIkdjZB94iMxtd2LMnkn4G1/BXLhgnyT8tQRD9ZeHEftLjiXwhBBCAndKO7divZSy1zneB0wZ4CFKkpQr0lEsFifEa4JNSsLhMGNjYzovbywW03mOU6nUBI+cIog+n097C5XXWWVigF0bYSiCpQhu6WYb6k9N05fIruVV8a6KECUSCU1wShdtlW6KUVqOWsw2NjY2wdurSJ7yYqs4WmVAqFAQv9+v202lGVNGg4rdVqRfxVqr9GZ+v1+HcyivZzgcZmhoSJen5Ojv79fxwblcjrGxsQmrhGOxmM71rAh2JBKhtrZW52zu7OxkbGxM/66e79DQEPl8nqGhoQm5nHfs2MHg4KDOYKGerdp5Tnm3BwYGtMdZtacyqNQKW5UYfmhoCL/fr0l2RUWFblPlDS4rK8Pr9eq8zKXPGXblelZhG6XkWL0X6jdl4Kn3SL0TiUSCBQsWEAgE2LhxI9lsVtd5BBcvHBZ9VRtZaKTTpL97O8U163ad7/GCEMh4nMw992HOa6d4988obt5KYeF8zGuuxPeWN4LHg++Nr0f29WP1D4Bh4r3wPLwXnmcTZrUAqKTDNhctJHLXnZDPI7MTNx/YTW7DhFCQyK3/YXuNB4cwmmcgyqKYs1omxAl7TjqRsrvuAMcgygH+z3zSXgCmGnBwGGt4mKJlYUXCSK8XIcB/3bW2zNkcRvMMjLoayh68j2Jnp+0J3raDwqo1UMjje8ub8Cw9fYKc2QceIv1f30PGxpzFN0598TiFlavxv/1qjAp7QW32vl9BJkPu8T8gvB5CX/kieDzkHv0tvjdegfD7SX3xK+D3U/aj72P1DxD8xL9i9fVh7ejAc9KJdvjLylXkV7xM4cWXMNtaCX7hc3jm7yKyhZdfJf3tW/G/+x345swGwKiIYp5wPFZPH9bwCKZKd9jRSeZ/fkBx02aEE4ua+/0T+N7wejiAAWryjOXePFlCCLyXXERk9iw7Nj3gn3IR56Eil8vxwx/+kFNOOYWlS5cebe/aQens3vTVe/aZWNu2Yy6YhzF7FsasmXtcZCedhZuBD70XY44T51pibAi/n+BHPrRH4c2TTiD8X98Cy0KmUsiBQfB6kekM1patiIZ6RDiEUVtD1OtDhELgMakArJ/9mOKODnxz2/FX7h7f7A+FeN3VV+2SOxxChEP4r/onjjv7LI4LBpDVVWRTaUaGh6hrbFRtw9zXX07rsmXIQgFPXS1Xff7fSMfjvPnt1zCydRvxQh7P4BA1M2ZQ6w/g223tgyT9/R+Q+/NTZIcG8fUPEvUYhDs7qGxqsQ19x1tpWRa/+MUvuO+++wgEAtx0002cccYZJBIJ29CKjTFyw8fImAZ1P78bfzDIqRbEZs9idj5PU9MMQuXlyJFRUl++heLqtYjqaiLf/TbmvPZdInV2kfnRTzDqagktXAChIGbrHIzmJjsEqiQfPNh9Tvan94Lfh+zrJ/vTewnd8qXdDKSjhcle+emK/Q2raJJSdgsh6oAngY8Bj0gpK0rOGZVS7jVy3+/3y/r6egzDoLKyUk93Syl1mpjR0VHtyVXhD6U72ylSAuyWy1KRYvWbIk9qJz1FDlW8rsqZWrrDGuxKCabIUimRUYRZEafSHf2UBzKbzeqdgBR5Ly8v18RobGyMTCZDNBqloqJC54tUJEzl8lUktNRbqYi3MgQmrFp1vJ3qfOEsNFB/KjOFMjjU9ZlMRocMqFAAQO8mpAirKlMlB1ekW22drBbGWZZFNBrVqbvUs1LPo1RmFaecc9IJqToAHSKiDBn13FXss4pHLt2xT5FS9YxKN3gohZJbbQKi7geYsJGIyhNZSoDVfZUaQY2NjdrrPTo6qnd4qq6uZubMmXR0dPDII4/o51tWVobP5+PBBx88EmEVh0Vfd5umlZLihk3kfvd7Ck89S3HnTszmJkR1FaGvfJHixs12XK1pQiaDMWf2XleKW5ZFIpHQxmBXVxe5XI7NmzfrOO18Pq8XsxqGwSWXXKJnYFR4zJlnnql37IvH41RWVk5YYb5y5Uqi0SgXX3zxbh3y2NgYt956qw6JUc/m1FNP5cQTT2T58uU89NBDtLS08OEPf1jHYA8MDLBu3To6Ozs599xzWb16NaFQiPPPPx9ZtOyZbGP37dpFJoM1PEJx6zakExdcLBbxNNTbHuKSDBLZe39JrH+AfDBARXU1ofPPhWSSwisr8Z57NiIcprhtB0ZDvSaquk9wsoAAkMshU2kwBCIc3m3aVUpJeniYlRs2UHB00+v1Mm/uXCKhMJjGhBk6ikVkMqljFoXXw3AmozeIaGpqorW1lfHxcVavXr3bLIkQgm3btrFq1Sra29t5//vfr9NJHSiklKxbt45XX32Viy++GI/Hw1//+leEEJx44onMdhY97Q8SiQQbNmzQm6FMhSMYVnHIOrvHMCj2TUTUGoADJSzJZJLHH3+cZDJJMBjUKdmam5t1+N9UGB8fZ+PGjRMWnbe0tLB9+3a6u7uprKzknHPOmehBdnZF3Lx5M4VCgXPOOYeVK1fS19eHaZq0t7czOjqKz+cjnU4zb9482tvb9e55XV1dWJZFY2Mjp59+On19fUQiESorK/X4NRlerxcyGYodXZp0inAYUV1pr0+Y9J7EYjE2btxIIpHgtNNO0+lhPR4PVrEIO7uxhEA2OhuEFIuY+QJCWohgkJyUrFu7lrmzZhEyTDsUK1KG8OyKfU6lUshikUKxiDAMveNuKjZGPpshUl2NYZp6XB0eHMSfLzAWi9nlhSNU19fpdLcq3ZtaTL527Vq9mL+6uprNmzfrPvfEE09k7ty5FAoFkskk5XtYH9DX10dfXx9tbW1EIhE2bNiAlJINGzYwOjpKPB6noaGByy+/XK/Xmjt37kFlQ9obDkVfDziVmxDiy0AC+CBwnpSyVwjRCPxFSjl/b9f6/X7Z0tKiX0SV+1XFtCriqzy7akMFRVTVAON1Ujapa4TYtf2qWhymSKLqdIvFop6mV8RFLaRT2RlUiIdaRAe7trxUscvj4+M6/GJ4eFjLqjy5ioiWxsWq2FSV6ULt7NfQ0KA3CykvL9cZNJQMajBSJFTtuqdSyIXDYf0yqQVygCbXKtG2Ch1R7VxKPAYGBnSeXrWhR+kCtNJ0b5FIRHuRS7cRLU07F4lEdMyvel4qNZwik4ogq3ZSA+/o6KjOgR0KhXReZfVcksmkvi9gAmEuFot6AZ+aAVCbykgpdf2maerc2Kqs0nhpdT/Kq63kUTMdihQroq+eg8rNq3ImK8NK5Zf+y1/+ojcsUbm9/X4/99577xFNDXUo+jrVYAvo+DaZydhky7LACUc6EPzoRz/izjvvpLW1VecbDQaDehvi+vp6FixYoDtg4cTlqxkoZTxHIhFisZhegHrqqadO8MpblqV3cJwq5lYZx+qdUO+lCs9KpVLkcjndL6j1EgMDA4yPj+sUjeqdU31baR1//vOf2b59O9dff/2EDAirV6/m0Ucf5dJLL+XUU08lm83y8MMP09DQwObNm3n11Vfp7Owkk8nQ0NCA1+vV2z2DTUJGR0cpFApcdNFFtLS0cDBIp9P8+te/5oUXXtA6WlZWppP5f+ADH9jrTEdvby9PPvkkUkoWLVrEkiVLGBkZ4fHHH9/NMK2srGTGjBkEAgFmz55N2IkTPRio8K/u7m7mzJlDWVmZXhBbGk51uHCkyPGkOr7MQejsnvT1SELluld576PRKOFwWOvQnpDJZNi8eTO1tbXaMFXx3SqMsXRnSYVSfVXjiOIwapxVY4Haxhrs8UEt+FezicooVxsT/f73v2d4eJhNmzbp82688UYaGxvZsWMHixcvZuXKlTz//PO0tbVx0UUXUSwWWbFiBaFQiAULFuxRR3p7e7nnnnuYOXOmzodumiZnnnkmxx13nL53taW6yqi1p7ZTCQ1UFqra2lpWrVpFMpmkurqaqqoqent7dYYvxV8UVJjktm3baG1t1X1m6VbsajZZraFS65ZUWlX1DPb0Xqh+RAihM4ClUin6+vrIZDLU1tbS3Nys+9kD3X57f3BEybEQIgwYUsq48/lJ4CvYu/YMy12LBaqklJ/eR1lxYOPBCHqEUQMM7fOsY4PpKtt0lQumr2xTyTVLSll7uCr4P6Kv8Np6xtMF01W26SoX7C7bYdVXOHw6K4QYBJJMz7Z8LT3j6QJXrgPHYdPX/SHHrcCvna8e4BdSyq8JIaqBXwEzgQ7sNDMj+yhrxZG2ug8GWW0SDAAABe5JREFU01UumL6yTVe5YPrKdjTk+r+grzB9ZZuucsH0lW26ygWuzh4uTFe5YPrK5sp14Dicsu1zQZ6Uchtw4hS/D2Nbti5cuJgmcPXVhYvXFlyddeFi+uEfJ5eHCxcuXLhw4cKFCxeHiKNNjn9wlOvbX0xXuWD6yjZd5YLpK9t0lWtPmM7yTlfZpqtcMH1lm65ywfSWbSpMV3mnq1wwfWVz5TpwHDbZDjhbhQsXLly4cOHChQsX/6hwwypcuHDhwoULFy5cuHDgkmMXLly4cOHChQsXLhwcFXIshLhMCLFRCLHFydd4VCGEaBFC/FkIsU4IsVYI8a/O71VCiCeFEJud/5XO70II8d+OvKuEEKccYflMIcQrQojlzvc5QogXnPrvF0L4nN/9zvctzvHZR1iuCiHEA0KIDUKI9UKIZdOhzYQQ/5/zHNcIIe4TQgSOVZsJIe4SQgwIIdaU/HbAbSSEeI9z/mYhxHumquto4ljqrKuvBy2Xq6/7lsXV18Nf97TWV6fOaaez01Vfnfqmhc4eU31VO50cqT/ABLYCrYAPWAksOtL1TpKhETjF+VwGbAIWAd8CPuv8/lng353PrwceAwSwFHjhCMv3CeAXwHLn+6+Atzuf7wA+4nz+KHCH8/ntwP1HWK6fAh9wPvuAimPdZkATsB0IlrTV9ceqzYDXAacAa0p+O6A2AqqAbc7/Sudz5ZF8tvu4p2Oqs66+HrRcrr7uWx5XXw9//dNaX506p53OTkd9deqaNjp7LPX1aCjOMuDxku+fAz53pOvdh0y/AS7G3v2r0fmtEdjofL4TuLbkfH3eEZClGfgjcAGw3HmwQ4BncvsBjwPLnM8e5zxxhOQqdxRETPr9mLaZo7hdzovucdrs0mPZZsDsScp7QG0EXAvcWfL7hPOO9t9001lXX/dLLldf918mV1+PrDzTRl+d8qedzk5XfXXKnlY6e6z09WiEVaiGVtjp/HZM4Lj8TwZeAOqllL3OoT6g3vl8NGW+Ffg0YDnfq///9u7nxcYojuP4+1sYoRi70SimZEtZTLFQNEliMztlwj9gKyt7KQvZkIVEMZNmp/xY+zElhJgiTJhJGWU16mtxvvd60jBzn7n3ec6Yz6tuzT3PrfOd7/SZzvPjdIFv7v5zlrmbdcXx6fh8J2wGpoDLcTvqoqWvNq21Z+4+AZwB3gOfSD0YI4+eNbTao6wyQkb1KK/zpryWp7y2SYZ5hTwzm2VeYVFktpK8LqkNeWa2BhgGTrj79+IxT6cUXnE9B4BJdx+rct55Wka6nXHB3bcDP0i3MJpq6lk3cIj0z2UDsBrYV2UNraijR/8L5bUlymsbKK/l5ZbXqCnXzGaZV1hcme1kj6pYHE8AGwvve2OsUma2nBTcq+4+EsNfzKwnjvcAkzFeVc07gYNm9g64Trrtcw5YZ2aNr/Yuzt2sK46vBb52oC5IZ1cf3f1BvL9JCnPdPdsLvHX3KXefAUZIfcyhZw2t9iiLjBTUXo/y2jLltTzldYEyzSvkm9lc8wr5Z7aSvFaxOH4EbImdjitID2yPVjBvk5kZcAl46e5nC4dGgaH4eYj0rFRj/EjsfuwHpguX8dvG3U+6e6+7byL15Z67HwbuA4N/qatR72B8viNnTe7+GfhgZltjaA/wgpp7RrrV029mq+Lv2qir9p4VtNqj28CAmXXHWftAjNWl1swqr6VqU17LU14XINe8Qr6ZzTivkH9mq8nrXA8lt+NF2kX4mrSj9lQVc/4x/y7SpfenwJN47Sc9F3MXeAPcAdbH5w04H/U+A3ZUUONufu+k7QMeAuPADaArxlfG+/E43tfhmrYBj6Nvt0g7PWvvGXAaeAU8B64AXXX1DLhGei5rhnQ14HiZHgHHosZx4GjVGZnl96ots8pr6ZqU17lrUV7bP3f2eY15s8psrnmN+bLIbJ151ddHi4iIiIiEJbUhT0RERETkX7Q4FhEREREJWhyLiIiIiAQtjkVEREREghbHIiIiIiJBi2MRERERkaDFsYiIiIhI+AUCQGP9A6q7oQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 3 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "#y_pred=model.predict(test_x)\n",
        "\n",
        "BGR_classes = {'a' : [ 0, 0, 0],\n",
        "                'b' : [255,  255, 255],\n",
        "                'c' : [36, 28, 237]} # in RGB #237,28,36\n",
        "\n",
        "bin_classes = ['a', 'b', 'c']\n",
        "\n",
        "\n",
        "ds = tf_dataset(test_x, test_y, batch=1)\n",
        "print(len(test_x))\n",
        "print(len(test_y))\n",
        "for x, y in ds:\n",
        "  print(x.shape, y.shape) ## (8, 256, 256, 3), (8, 256, 256, 3)\n",
        "\n",
        "  y_pred=model.predict(x)\n",
        "  print(y_pred.shape)\n",
        "  y_pred=np.argmax(y_pred,axis=3)[0,:,:]\n",
        "\n",
        "\n",
        "\n",
        "  plt.figure(figsize=(12, 8))\n",
        "  plt.subplot(231)\n",
        "  plt.title('Testing Image')\n",
        "  plt.imshow(x[0,:,:,0], cmap='gray') # Works\n",
        "  #plt.imshow(cv2.cvtColor(x[:,:,0].astype(np.uint8),cv2.COLOR_BGR2RGB))\n",
        "\n",
        "\n",
        "  plt.subplot(232)\n",
        "  plt.title('Testing Label')\n",
        "  ys=np.argmax(y,axis=3)[0,:,:]\n",
        "  se = set({})\n",
        "  im1 = []\n",
        "  for i in ys : \n",
        "    row = []\n",
        "    for k in i :\n",
        "        row.append(BGR_classes[bin_classes[k]])\n",
        "    im1.append(row)\n",
        "  im1_np=np.array(im1)\n",
        "  plt.imshow(cv2.cvtColor(im1_np.astype(np.uint8),cv2.COLOR_BGR2RGB))\n",
        "  #plt.imshow(ys, cmap='jet')\n",
        "\n",
        "\n",
        "  plt.subplot(233)\n",
        "  plt.title('Prediction on test image')\n",
        "  se = set({})\n",
        "  im3 = []\n",
        "  for i in y_pred : \n",
        "    row = []\n",
        "    for k in i :\n",
        "        row.append(BGR_classes[bin_classes[k]])\n",
        "    im3.append(row)\n",
        "  im3_np=np.array(im3)\n",
        "  plt.imshow(cv2.cvtColor(im3_np.astype(np.uint8),cv2.COLOR_BGR2RGB))\n",
        "\n",
        "  \n",
        "  #plt.imshow(y_pred, cmap='jet')\n",
        "  break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1-nPd7NwS_MchbHetrYQiptTU0r06aoOo",
      "authorship_tag": "ABX9TyPF7Zb9uxLgu5cjaI/ulf+I",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}